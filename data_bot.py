import streamlit as st
import pandas as pd
from google.oauth2 import service_account
from googleapiclient.discovery import build
import io
import os
import re

# ==========================================
# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø§ØªØµØ§Ù„
# ==========================================
FOLDER_ID = "1kgzKj9sn8pQVjr78XcN7_iF5KLmflwME"
SCOPES = ['https://www.googleapis.com/auth/drive.readonly']

# ==========================================
# 2. Ù‚Ø§Ù…ÙˆØ³ ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
# ==========================================
COLUMN_MAPPING = {
    # Ø§Ù„Ø³Ø¹Ø±
    'Ø§Ù„Ø³Ø¹Ø±': 'Ø§Ù„Ø³Ø¹Ø±', 'Ù‚ÙŠÙ…Ø© Ø§Ù„ØµÙÙ‚Ø§Øª': 'Ø§Ù„Ø³Ø¹Ø±', 'Price': 'Ø§Ù„Ø³Ø¹Ø±', 'Ø§Ù„Ù‚ÙŠÙ…Ø©': 'Ø§Ù„Ø³Ø¹Ø±',
    # Ø§Ù„Ù…Ø³Ø§Ø­Ø©
    'Ø§Ù„Ù…Ø³Ø§Ø­Ø©': 'Ø§Ù„Ù…Ø³Ø§Ø­Ø©', 'Ø§Ù„Ù…Ø³Ø§Ø­Ø© M2': 'Ø§Ù„Ù…Ø³Ø§Ø­Ø©', 'Area': 'Ø§Ù„Ù…Ø³Ø§Ø­Ø©', 'Ù…Ø³Ø§Ø­Ø©': 'Ø§Ù„Ù…Ø³Ø§Ø­Ø©',
    # Ø§Ù„Ù…ÙˆÙ‚Ø¹
    'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©': 'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©', 'City': 'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©',
    'Ø§Ù„Ø­ÙŠ': 'Ø§Ù„Ø­ÙŠ', 'Ø§Ø³Ù… Ø§Ù„Ø­ÙŠ': 'Ø§Ù„Ø­ÙŠ', 'District': 'Ø§Ù„Ø­ÙŠ', 'Location': 'Ø§Ù„Ø­ÙŠ',
    # Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬
    'Ø§Ø³Ù… Ø§Ù„Ù…Ø´Ø±ÙˆØ¹': 'Ø§Ø³Ù…_Ø§Ù„Ù…Ø´Ø±ÙˆØ¹_Ø§Ù„Ø®Ø§Ù…', 'Ø§Ù„Ù…Ø´Ø±ÙˆØ¹': 'Ø§Ø³Ù…_Ø§Ù„Ù…Ø´Ø±ÙˆØ¹_Ø§Ù„Ø®Ø§Ù…', 'Project Name': 'Ø§Ø³Ù…_Ø§Ù„Ù…Ø´Ø±ÙˆØ¹_Ø§Ù„Ø®Ø§Ù…',
    'Ø§Ù„Ù…Ø®Ø·Ø·': 'Ø§Ø³Ù…_Ø§Ù„Ù…Ø´Ø±ÙˆØ¹_Ø§Ù„Ø®Ø§Ù…',
    # Ø§Ù„ØªÙØ§ØµÙŠÙ„
    'Ù†ÙˆØ¹ Ø§Ù„Ø¹Ù‚Ø§Ø±': 'Ù†ÙˆØ¹_Ø§Ù„Ø¹Ù‚Ø§Ø±_Ø§Ù„Ø®Ø§Ù…', 'ØªØµÙ†ÙŠÙ Ø§Ù„Ø¹Ù‚Ø§Ø±': 'Ù†ÙˆØ¹_Ø§Ù„Ø¹Ù‚Ø§Ø±_Ø§Ù„Ø®Ø§Ù…', 'Ø§Ù„Ù†ÙˆØ¹': 'Ù†ÙˆØ¹_Ø§Ù„Ø¹Ù‚Ø§Ø±_Ø§Ù„Ø®Ø§Ù…',
    'Ø§Ù„Ø­Ø§Ù„Ø©': 'Ø§Ù„Ø­Ø§Ù„Ø©', 'Status': 'Ø§Ù„Ø­Ø§Ù„Ø©',
    'Ø¹Ø¯Ø¯ Ø§Ù„ØºØ±Ù': 'Ø¹Ø¯Ø¯_Ø§Ù„ØºØ±Ù', 'ØºØ±Ù': 'Ø¹Ø¯Ø¯_Ø§Ù„ØºØ±Ù',
    # Ø¥Ø¶Ø§ÙØ§Øª
    'Ø¹Ø¯Ø¯ Ø§Ù„ØµÙƒÙˆÙƒ': 'Ø¹Ø¯Ø¯_Ø§Ù„ØµÙƒÙˆÙƒ', 'Ø§Ù„Ù…Ø·ÙˆØ±': 'Ø§Ø³Ù…_Ø§Ù„Ù…Ø·ÙˆØ±'
}

class RealEstateBot:
    def __init__(self):
        self.creds = self.get_creds()
        self.service = build('drive', 'v3', credentials=self.creds)
        self.df = self.load_data_from_drive()

    def get_creds(self):
        if 'gcp_service_account' in st.secrets:
            return service_account.Credentials.from_service_account_info(st.secrets['gcp_service_account'], scopes=SCOPES)
        elif os.path.exists('credentials.json'):
            return service_account.Credentials.from_service_account_file('credentials.json', scopes=SCOPES)
        return None

    def load_data_from_drive(self):
        all_data = []
        if not self.creds: return pd.DataFrame()
        
        try:
            results = self.service.files().list(q=f"'{FOLDER_ID}' in parents and trashed=false", fields="files(id, name)").execute()
            files = results.get('files', [])
            
            for file in files:
                if not file['name'].lower().endswith('.csv'): continue
                try:
                    # 1. Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù
                    request = self.service.files().get_media(fileId=file['id'])
                    content_bytes = request.execute()
                    try: content_str = content_bytes.decode('utf-8-sig')
                    except: content_str = content_bytes.decode('utf-16')
                    
                    # 2. ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù‡ÙŠØ¯Ø±
                    lines = content_str.splitlines()
                    header_idx = 0; sep = ','
                    for i, line in enumerate(lines[:50]):
                        if ('Ø§Ù„Ø³Ø¹Ø±' in line or 'Price' in line) and ('Ø§Ù„Ù…Ø³Ø§Ø­Ø©' in line or 'Area' in line):
                            header_idx = i
                            sep = ';' if ';' in line else '\t' if '\t' in line else ','
                            break
                    
                    df_temp = pd.read_csv(io.StringIO(content_str), sep=sep, header=header_idx, engine='python')

                    # 3. ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ù„Ù (Ø¹Ø±ÙˆØ¶ vs ØµÙÙ‚Ø§Øª)
                    fname = file['name'].lower()
                    data_cat = "Ø¹Ø±ÙˆØ¶ (Ask)" if ("Ø¹Ø±ÙˆØ¶" in fname or "offer" in fname) else "ØµÙÙ‚Ø§Øª (Sold)"
                    source_type = 'Ø¹Ø¯Ù„' if ('MOJ' in file['name'].upper()) else ('Ù…Ø·ÙˆØ±ÙŠÙ†' if any(x in fname for x in ['dev', 'Ù…Ø·ÙˆØ±']) else 'Ø¹Ø§Ù…')

                    # 4. ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
                    df_temp.columns = df_temp.columns.str.strip()
                    df_temp.rename(columns=COLUMN_MAPPING, inplace=True)
                    df_temp = df_temp.loc[:, ~df_temp.columns.duplicated()]

                    # =========================================================
                    # ğŸ•µï¸â€â™‚ï¸ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø­ÙŠ Ø§Ù„Ù…ÙÙ‚ÙˆØ¯ (ÙƒÙ…Ø§ Ø§ØªÙÙ‚Ù†Ø§ Ø³Ø§Ø¨Ù‚Ø§Ù‹)
                    # =========================================================
                    if 'Ø§Ù„Ø­ÙŠ' not in df_temp.columns: df_temp['Ø§Ù„Ø­ÙŠ'] = None
                    if 'Ø§Ø³Ù…_Ø§Ù„Ù…Ø´Ø±ÙˆØ¹_Ø§Ù„Ø®Ø§Ù…' not in df_temp.columns: df_temp['Ø§Ø³Ù…_Ø§Ù„Ù…Ø´Ø±ÙˆØ¹_Ø§Ù„Ø®Ø§Ù…'] = ''

                    bad_mask = df_temp['Ø§Ù„Ø­ÙŠ'].isna() | df_temp['Ø§Ù„Ø­ÙŠ'].astype(str).str.contains(r'Ø¬Ù…ÙŠØ¹|All|Ù…Ø´Ø±ÙˆØ¹|Ø¹Ø§Ù…', case=False, na=False) | (df_temp['Ø§Ù„Ø­ÙŠ'].astype(str).str.len() < 3)

                    # ØªÙƒØªÙŠÙƒ 1: Ø§Ø³ØªØ®Ø±Ø§Ø¬ "Ø­ÙŠ ÙƒØ°Ø§" Ù…Ù† Ø§Ø³Ù… Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
                    def extract_with_prefix(text):
                        if pd.isna(text): return None
                        match = re.search(r'(?:Ø­ÙŠ|Ù…Ø®Ø·Ø·)\s+([\w\u0600-\u06FF]+)', str(text))
                        return match.group(1).strip() if match else None

                    df_temp.loc[bad_mask, 'Ø§Ù„Ø­ÙŠ'] = df_temp.loc[bad_mask, 'Ø§Ø³Ù…_Ø§Ù„Ù…Ø´Ø±ÙˆØ¹_Ø§Ù„Ø®Ø§Ù…'].apply(extract_with_prefix)
                    
                    # ØªÙƒØªÙŠÙƒ 2: Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù ÙƒØ®ÙŠØ§Ø± Ø£Ø®ÙŠØ±
                    potential_dist_file = file['name'].replace('.csv', '').replace('.CSV', '')
                    for w in ['Ø¹Ø±ÙˆØ¶', 'ØµÙÙ‚Ø§Øª', 'Offers', 'Sold', 'Ø§Ù„Ø±ÙŠØ§Ø¶', 'Riyadh', 'Ø­ÙŠ', 'District', '_', '-']:
                        potential_dist_file = potential_dist_file.replace(w, ' ')
                    
                    df_temp['Ø§Ù„Ø­ÙŠ'] = df_temp['Ø§Ù„Ø­ÙŠ'].fillna(potential_dist_file.strip())
                    # =========================================================

                    # 5. Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ©
                    if 'Ø§Ù„Ø³Ø¹Ø±' in df_temp.columns and 'Ø§Ù„Ù…Ø³Ø§Ø­Ø©' in df_temp.columns:
                        for col in ['Ø§Ù„Ø³Ø¹Ø±', 'Ø§Ù„Ù…Ø³Ø§Ø­Ø©', 'Ø¹Ø¯Ø¯_Ø§Ù„ØºØ±Ù']:
                            if col in df_temp.columns:
                                df_temp[col] = df_temp[col].astype(str).str.replace(',', '').str.replace(r'[^\d.]', '', regex=True)
                                df_temp[col] = pd.to_numeric(df_temp[col], errors='coerce')
                        
                        df_temp.dropna(subset=['Ø§Ù„Ø³Ø¹Ø±', 'Ø§Ù„Ù…Ø³Ø§Ø­Ø©'], inplace=True)
                        df_temp = df_temp[df_temp['Ø§Ù„Ù…Ø³Ø§Ø­Ø©'] > 0]
                        
                        df_temp['Ø³Ø¹Ø±_Ø§Ù„Ù…ØªØ±'] = df_temp['Ø§Ù„Ø³Ø¹Ø±'] / df_temp['Ø§Ù„Ù…Ø³Ø§Ø­Ø©']
                        df_temp['Source_File'] = file['name']
                        df_temp['Source_Type'] = source_type
                        df_temp['Data_Category'] = data_cat
                        
                        # Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„Ù†ÙˆØ§Ù‚Øµ
                        for c in ['Ù†ÙˆØ¹_Ø§Ù„Ø¹Ù‚Ø§Ø±_Ø§Ù„Ø®Ø§Ù…', 'Ø§Ù„Ø­Ø§Ù„Ø©', 'Ø¹Ø¯Ø¯_Ø§Ù„ØºØ±Ù', 'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©', 'Ø§Ø³Ù…_Ø§Ù„Ù…Ø·ÙˆØ±', 'Ø¹Ø¯Ø¯_Ø§Ù„ØµÙƒÙˆÙƒ', 'Ø§Ø³Ù…_Ø§Ù„Ù…Ø´Ø±ÙˆØ¹_Ø§Ù„Ø®Ø§Ù…']: 
                            if c not in df_temp.columns: df_temp[c] = None 
                        
                        cols = ['Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©', 'Ø§Ù„Ø­ÙŠ', 'Ø§Ù„Ø³Ø¹Ø±', 'Ø§Ù„Ù…Ø³Ø§Ø­Ø©', 'Ø³Ø¹Ø±_Ø§Ù„Ù…ØªØ±', 
                                'Ù†ÙˆØ¹_Ø§Ù„Ø¹Ù‚Ø§Ø±_Ø§Ù„Ø®Ø§Ù…', 'Ø§Ù„Ø­Ø§Ù„Ø©', 'Ø¹Ø¯Ø¯_Ø§Ù„ØºØ±Ù',
                                'Source_File', 'Source_Type', 'Data_Category', 'Ø§Ø³Ù…_Ø§Ù„Ù…Ø´Ø±ÙˆØ¹_Ø§Ù„Ø®Ø§Ù…']
                        
                        final_cols = [c for c in cols if c in df_temp.columns]
                        all_data.append(df_temp[final_cols])

                except Exception as e:
                    print(f"Skipping {file['name']}: {e}")

            if all_data:
                total_df = pd.concat(all_data, ignore_index=True)
                
                # Ø­Ø³Ø§Ø¨ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø­ÙŠ (Ù„Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬ ÙÙŠ Ø§Ù„ØµÙÙ‚Ø§Øª ÙÙ‚Ø·)
                medians = {}
                if 'Ø§Ù„Ø­ÙŠ' in total_df.columns:
                    # Ù†Ø­Ø³Ø¨ Ø§Ù„Ù…ØªÙˆØ³Ø· ÙÙ‚Ø· Ù„Ù„ØµÙÙ‚Ø§Øª Ø§Ù„Ù…ØµÙ†ÙØ© ÙƒØ£Ø±Ø¶ Ù…Ø¨Ø¯Ø¦ÙŠØ§Ù‹ Ù„ÙŠÙƒÙˆÙ† Ù…Ø¹ÙŠØ§Ø±Ø§Ù‹
                    land_only = total_df[total_df['Ù†ÙˆØ¹_Ø§Ù„Ø¹Ù‚Ø§Ø±_Ø§Ù„Ø®Ø§Ù…'].astype(str).str.contains('Ø£Ø±Ø¶', na=False)]
                    medians = land_only.groupby('Ø§Ù„Ø­ÙŠ')['Ø³Ø¹Ø±_Ø§Ù„Ù…ØªØ±'].median().to_dict()

                # =========================================================
                # ğŸ§  Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ø²Ø¯ÙˆØ¬Ø© (Dual Classification Logic)
                # =========================================================
                def classify_property(row):
                    raw = str(row.get('Ù†ÙˆØ¹_Ø§Ù„Ø¹Ù‚Ø§Ø±_Ø§Ù„Ø®Ø§Ù…', '')).strip().lower()
                    category = row.get('Data_Category', '')
                    
                    # -----------------------------------
                    # Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 1: Ø§Ù„Ø¹Ø±ÙˆØ¶ (Offers)
                    # -----------------------------------
                    # Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø©: Ø®Ø° Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ù„Ù ÙƒÙ…Ø§ Ù‡ÙŠØŒ ÙˆØ­Ø¯Ø¯ Ø§Ù„Ù†ÙˆØ¹ Ø¨Ø¯Ù‚Ø© (Ø¯ÙˆØ±ØŒ Ø´Ù‚Ø©ØŒ ÙÙŠÙ„Ø§)
                    if 'Ø¹Ø±ÙˆØ¶' in category or 'Ask' in category:
                        if 'Ø£Ø±Ø¶' in raw or 'land' in raw: return "Ø£Ø±Ø¶"
                        if 'Ø¯ÙˆØ±' in raw or 'floor' in raw: return "Ø¯ÙˆØ±"
                        if 'Ø´Ù‚Ø©' in raw or 'apartment' in raw: return "Ø´Ù‚Ø©"
                        if any(x in raw for x in ['ÙÙŠÙ„Ø§', 'ÙÙ„Ù‡', 'villa', 'Ø¨ÙŠØª', 'ØªØ§ÙˆÙ†']): return "ÙÙŠÙ„Ø§"
                        if 'Ø¹Ù…Ø§Ø±Ø©' in raw or 'building' in raw: return "Ø¹Ù…Ø§Ø±Ø©"
                        
                        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†ÙˆØ¹ ÙØ§Ø±ØºØ§Ù‹ ÙÙŠ Ù…Ù„Ù Ø§Ù„Ø¹Ø±ÙˆØ¶ØŒ Ø­Ø§ÙˆÙ„ Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø­Ø© ÙƒØ­Ù„ Ø£Ø®ÙŠØ±
                        area = row.get('Ø§Ù„Ù…Ø³Ø§Ø­Ø©', 0)
                        if not raw or raw == 'nan' or raw == 'none':
                            if area > 0 and area < 250: return "Ø´Ù‚Ø©" # Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù„Ù„Ù…Ø³Ø§Ø­Ø§Øª Ø§Ù„ØµØºÙŠØ±Ø©
                            if area > 250: return "ÙÙŠÙ„Ø§" # Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù„Ù„Ù…Ø³Ø§Ø­Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø©
                        
                        return raw # Ø¥Ø°Ø§ Ù„Ù… ÙŠØªØ·Ø§Ø¨Ù‚ØŒ Ø£Ø±Ø¬Ø¹ Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ ÙƒÙ…Ø§ Ù‡Ùˆ

                    # -----------------------------------
                    # Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 2: Ø§Ù„ØµÙÙ‚Ø§Øª (Deals)
                    # -----------------------------------
                    # Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø©: Ø­Ø¯Ø¯ Ù‡Ù„ Ù‡Ùˆ Ù…Ø¨Ù†ÙŠ Ø£Ù… Ù„Ø§ (Binary Classification)
                    else:
                        # Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„ØµØ±ÙŠØ­
                        if 'Ø£Ø±Ø¶' in raw or 'land' in raw: return "Ø£Ø±Ø¶"
                        if any(x in raw for x in ['ÙÙŠÙ„Ø§', 'Ø¨ÙŠØª', 'Ø´Ù‚Ø©', 'Ø¹Ù…Ø§Ø±Ø©', 'Ø¯ÙˆØ±', 'Ø³ÙƒÙ†ÙŠ ØªØ¬Ø§Ø±ÙŠ']): return "Ù…Ø¨Ù†ÙŠ"

                        # Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø§Ù„Ø°ÙƒÙŠ (Heuristic) Ù„Ù„ØµÙÙ‚Ø§Øª Ø§Ù„Ù…Ø¨Ù‡Ù…Ø©
                        area = row.get('Ø§Ù„Ù…Ø³Ø§Ø­Ø©', 0)
                        ppm = row.get('Ø³Ø¹Ø±_Ø§Ù„Ù…ØªØ±', 0)
                        dist = row.get('Ø§Ù„Ø­ÙŠ', '')
                        
                        avg_land_price = medians.get(dist, 0)
                        
                        # Ø¥Ø°Ø§ Ø§Ù„Ø³Ø¹Ø± Ø£ØºÙ„Ù‰ Ù…Ù† Ù…ØªÙˆØ³Ø· Ø£Ø±Ø§Ø¶ÙŠ Ø§Ù„Ø­ÙŠ Ø¨Ù€ 50% -> ØºØ§Ù„Ø¨Ø§Ù‹ Ù…Ø¨Ù†ÙŠ
                        if avg_land_price > 0 and ppm > (avg_land_price * 1.5):
                            return "Ù…Ø¨Ù†ÙŠ"
                        
                        return "Ø£Ø±Ø¶" # Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ ÙÙŠ Ø§Ù„ØµÙÙ‚Ø§Øª Ù‡Ùˆ Ø§Ù„Ø£Ø±Ø¶

                total_df['Ù†ÙˆØ¹_Ø§Ù„Ø¹Ù‚Ø§Ø±'] = total_df.apply(classify_property, axis=1)
                return total_df
            
            return pd.DataFrame()
        except: return pd.DataFrame()
