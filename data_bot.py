import streamlit as st
import pandas as pd
from google.oauth2 import service_account
from googleapiclient.discovery import build
import io
import os
import re

# ==========================================
# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø§ØªØµØ§Ù„
# ==========================================
FOLDER_ID = "1kgzKj9sn8pQVjr78XcN7_iF5KLmflwME"
SCOPES = ['https://www.googleapis.com/auth/drive.readonly']

# ==========================================
# 2. Ù‚Ø§Ù…ÙˆØ³ ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
# ==========================================
COLUMN_MAPPING = {
    # Ø§Ù„Ø³Ø¹Ø±
    'Ø§Ù„Ø³Ø¹Ø±': 'Ø§Ù„Ø³Ø¹Ø±', 'Ù‚ÙŠÙ…Ø© Ø§Ù„ØµÙÙ‚Ø§Øª': 'Ø§Ù„Ø³Ø¹Ø±', 'Price': 'Ø§Ù„Ø³Ø¹Ø±', 'Ø§Ù„Ù‚ÙŠÙ…Ø©': 'Ø§Ù„Ø³Ø¹Ø±',
    # Ø§Ù„Ù…Ø³Ø§Ø­Ø©
    'Ø§Ù„Ù…Ø³Ø§Ø­Ø©': 'Ø§Ù„Ù…Ø³Ø§Ø­Ø©', 'Ø§Ù„Ù…Ø³Ø§Ø­Ø© M2': 'Ø§Ù„Ù…Ø³Ø§Ø­Ø©', 'Area': 'Ø§Ù„Ù…Ø³Ø§Ø­Ø©', 'Ù…Ø³Ø§Ø­Ø©': 'Ø§Ù„Ù…Ø³Ø§Ø­Ø©',
    # Ø§Ù„Ù…ÙˆÙ‚Ø¹
    'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©': 'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©', 'City': 'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©',
    'Ø§Ù„Ø­ÙŠ': 'Ø§Ù„Ø­ÙŠ', 'Ø§Ø³Ù… Ø§Ù„Ø­ÙŠ': 'Ø§Ù„Ø­ÙŠ', 'District': 'Ø§Ù„Ø­ÙŠ', 'Location': 'Ø§Ù„Ø­ÙŠ',
    # Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬
    'Ø§Ø³Ù… Ø§Ù„Ù…Ø´Ø±ÙˆØ¹': 'Ø§Ø³Ù…_Ø§Ù„Ù…Ø´Ø±ÙˆØ¹_Ø§Ù„Ø®Ø§Ù…', 'Ø§Ù„Ù…Ø´Ø±ÙˆØ¹': 'Ø§Ø³Ù…_Ø§Ù„Ù…Ø´Ø±ÙˆØ¹_Ø§Ù„Ø®Ø§Ù…', 'Project Name': 'Ø§Ø³Ù…_Ø§Ù„Ù…Ø´Ø±ÙˆØ¹_Ø§Ù„Ø®Ø§Ù…',
    'Ø§Ù„Ù…Ø®Ø·Ø·': 'Ø§Ø³Ù…_Ø§Ù„Ù…Ø´Ø±ÙˆØ¹_Ø§Ù„Ø®Ø§Ù…',
    # Ø§Ù„ØªÙØ§ØµÙŠÙ„
    'Ù†ÙˆØ¹ Ø§Ù„Ø¹Ù‚Ø§Ø±': 'Ù†ÙˆØ¹_Ø§Ù„Ø¹Ù‚Ø§Ø±_Ø§Ù„Ø®Ø§Ù…', 'ØªØµÙ†ÙŠÙ Ø§Ù„Ø¹Ù‚Ø§Ø±': 'Ù†ÙˆØ¹_Ø§Ù„Ø¹Ù‚Ø§Ø±_Ø§Ù„Ø®Ø§Ù…', 'Ø§Ù„Ù†ÙˆØ¹': 'Ù†ÙˆØ¹_Ø§Ù„Ø¹Ù‚Ø§Ø±_Ø§Ù„Ø®Ø§Ù…',
    'Ø§Ù„Ø­Ø§Ù„Ø©': 'Ø§Ù„Ø­Ø§Ù„Ø©', 'Status': 'Ø§Ù„Ø­Ø§Ù„Ø©',
    'Ø¹Ø¯Ø¯ Ø§Ù„ØºØ±Ù': 'Ø¹Ø¯Ø¯_Ø§Ù„ØºØ±Ù', 'ØºØ±Ù': 'Ø¹Ø¯Ø¯_Ø§Ù„ØºØ±Ù',
    # Ø¥Ø¶Ø§ÙØ§Øª
    'Ø¹Ø¯Ø¯ Ø§Ù„ØµÙƒÙˆÙƒ': 'Ø¹Ø¯Ø¯_Ø§Ù„ØµÙƒÙˆÙƒ', 'Ø§Ù„Ù…Ø·ÙˆØ±': 'Ø§Ø³Ù…_Ø§Ù„Ù…Ø·ÙˆØ±'
}

class RealEstateBot:
    def __init__(self):
        self.creds = self.get_creds()
        self.service = build('drive', 'v3', credentials=self.creds)
        self.df = self.load_data_from_drive()

    def get_creds(self):
        if 'gcp_service_account' in st.secrets:
            return service_account.Credentials.from_service_account_info(st.secrets['gcp_service_account'], scopes=SCOPES)
        elif os.path.exists('credentials.json'):
            return service_account.Credentials.from_service_account_file('credentials.json', scopes=SCOPES)
        return None

    def load_data_from_drive(self):
        all_data = []
        if not self.creds: return pd.DataFrame()
        
        try:
            results = self.service.files().list(q=f"'{FOLDER_ID}' in parents and trashed=false", fields="files(id, name)").execute()
            files = results.get('files', [])
            
            for file in files:
                if not file['name'].lower().endswith('.csv'): continue
                try:
                    # 1. Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù
                    request = self.service.files().get_media(fileId=file['id'])
                    content_bytes = request.execute()
                    try: content_str = content_bytes.decode('utf-8-sig')
                    except: content_str = content_bytes.decode('utf-16')
                    
                    # 2. ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù‡ÙŠØ¯Ø±
                    lines = content_str.splitlines()
                    header_idx = 0; sep = ','
                    for i, line in enumerate(lines[:50]):
                        if ('Ø§Ù„Ø³Ø¹Ø±' in line or 'Price' in line) and ('Ø§Ù„Ù…Ø³Ø§Ø­Ø©' in line or 'Area' in line):
                            header_idx = i
                            sep = ';' if ';' in line else '\t' if '\t' in line else ','
                            break
                    
                    df_temp = pd.read_csv(io.StringIO(content_str), sep=sep, header=header_idx, engine='python')

                    # 3. ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ù„Ù
                    fname = file['name'].lower()
                    data_cat = "Ø¹Ø±ÙˆØ¶ (Ask)" if ("Ø¹Ø±ÙˆØ¶" in fname or "offer" in fname) else "ØµÙÙ‚Ø§Øª (Sold)"
                    source_type = 'Ø¹Ø¯Ù„' if ('MOJ' in file['name'].upper()) else ('Ù…Ø·ÙˆØ±ÙŠÙ†' if any(x in fname for x in ['dev', 'Ù…Ø·ÙˆØ±']) else 'Ø¹Ø§Ù…')

                    # 4. ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
                    df_temp.columns = df_temp.columns.str.strip()
                    df_temp.rename(columns=COLUMN_MAPPING, inplace=True)
                    df_temp = df_temp.loc[:, ~df_temp.columns.duplicated()]

                    # =========================================================
                    # ğŸ•µï¸â€â™‚ï¸ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø£Ø­ÙŠØ§Ø¡ (ØªÙ… Ø¥Ø¶Ø§ÙØ© "Ø±Ø§ÙƒØ²" Ù„Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø³ÙˆØ¯Ø§Ø¡)
                    # =========================================================
                    if 'Ø§Ù„Ø­ÙŠ' not in df_temp.columns: df_temp['Ø§Ù„Ø­ÙŠ'] = None
                    if 'Ø§Ø³Ù…_Ø§Ù„Ù…Ø´Ø±ÙˆØ¹_Ø§Ù„Ø®Ø§Ù…' not in df_temp.columns: df_temp['Ø§Ø³Ù…_Ø§Ù„Ù…Ø´Ø±ÙˆØ¹_Ø§Ù„Ø®Ø§Ù…'] = ''

                    # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØªÙŠ Ø¥Ø°Ø§ ÙˆØ¬Ø¯Øª ÙÙŠ Ø®Ø§Ù†Ø© Ø§Ù„Ø­ÙŠ Ù†Ø¹ØªØ¨Ø±Ù‡Ø§ Ø®Ø§Ù†Ø© "ØªØ§Ù„ÙØ©" ÙˆÙŠØ¬Ø¨ Ø¥ØµÙ„Ø§Ø­Ù‡Ø§
                    # Ø£Ø¶ÙÙ†Ø§ "Ø±Ø§ÙƒØ²" Ù‡Ù†Ø§ ğŸ‘‡
                    invalid_words = r'Ø¬Ù…ÙŠØ¹|All|Ù…Ø´Ø±ÙˆØ¹|Project|Ø¹Ø§Ù…|Ø±Ø§ÙƒØ²|Rakez'
                    
                    bad_mask = df_temp['Ø§Ù„Ø­ÙŠ'].isna() | \
                               df_temp['Ø§Ù„Ø­ÙŠ'].astype(str).str.contains(invalid_words, case=False, na=False) | \
                               (df_temp['Ø§Ù„Ø­ÙŠ'].astype(str).str.len() < 3)

                    # ØªÙƒØªÙŠÙƒ 1: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ø­ÙŠ Ù…Ù† "Ø§Ø³Ù… Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"
                    def extract_with_prefix(text):
                        if pd.isna(text): return None
                        # ÙŠØ¨Ø­Ø« Ø¹Ù† ÙƒÙ„Ù…Ø© Ø¨Ø¹Ø¯ "Ø­ÙŠ" Ø£Ùˆ "Ù…Ø®Ø·Ø·"
                        match = re.search(r'(?:Ø­ÙŠ|Ù…Ø®Ø·Ø·)\s+([\w\u0600-\u06FF]+)', str(text))
                        if match:
                            extracted = match.group(1).strip()
                            # ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ù„ÙŠØ³ "Ø±Ø§ÙƒØ²" Ø£ÙŠØ¶Ø§Ù‹
                            if 'Ø±Ø§ÙƒØ²' in extracted or 'Rakez' in extracted: return None
                            return extracted
                        return None

                    df_temp.loc[bad_mask, 'Ø§Ù„Ø­ÙŠ'] = df_temp.loc[bad_mask, 'Ø§Ø³Ù…_Ø§Ù„Ù…Ø´Ø±ÙˆØ¹_Ø§Ù„Ø®Ø§Ù…'].apply(extract_with_prefix)
                    
                    # ØªÙƒØªÙŠÙƒ 2: Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹ÙƒØ³ÙŠ (Ø¥Ø°Ø§ ÙˆØ¬Ø¯Ù†Ø§ Ø£Ø³Ù…Ø§Ø¡ Ø£Ø­ÙŠØ§Ø¡ ØµØ­ÙŠØ­Ø© ÙÙŠ Ø§Ù„Ù…Ù„ÙØŒ Ù†Ø³ØªØ®Ø¯Ù…Ù‡Ø§ Ù„ØªØµØ­ÙŠØ­ Ø§Ù„Ø¨Ù‚ÙŠØ©)
                    # Ù†Ø¹ÙŠØ¯ Ø­Ø³Ø§Ø¨ bad_mask Ù„Ø£Ù† Ø¨Ø¹Ø¶ Ø§Ù„ØµÙÙˆÙ Ù‚Ø¯ ØªÙƒÙˆÙ† ØªØµÙ„Ø­Øª
                    bad_mask = df_temp['Ø§Ù„Ø­ÙŠ'].isna() | df_temp['Ø§Ù„Ø­ÙŠ'].astype(str).str.contains(invalid_words, case=False, na=False)
                    
                    valid_districts = df_temp.loc[~bad_mask, 'Ø§Ù„Ø­ÙŠ'].unique()
                    valid_districts = [d for d in valid_districts if isinstance(d, str) and len(d) > 2]

                    if len(valid_districts) > 0 and bad_mask.any():
                        pattern = '|'.join([re.escape(d) for d in valid_districts])
                        def find_known_district(text):
                            if pd.isna(text): return None
                            match = re.search(pattern, str(text))
                            return match.group(0) if match else None

                        found = df_temp.loc[bad_mask, 'Ø§Ø³Ù…_Ø§Ù„Ù…Ø´Ø±ÙˆØ¹_Ø§Ù„Ø®Ø§Ù…'].apply(find_known_district)
                        df_temp.loc[bad_mask, 'Ø§Ù„Ø­ÙŠ'] = found.combine_first(df_temp.loc[bad_mask, 'Ø§Ù„Ø­ÙŠ'])

                    # ØªÙƒØªÙŠÙƒ 3: Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù (Ø§Ù„Ù…Ù„Ø§Ø° Ø§Ù„Ø£Ø®ÙŠØ±)
                    potential_dist_file = file['name'].replace('.csv', '').replace('.CSV', '')
                    for w in ['Ø¹Ø±ÙˆØ¶', 'ØµÙÙ‚Ø§Øª', 'Offers', 'Sold', 'Ø§Ù„Ø±ÙŠØ§Ø¶', 'Riyadh', 'Ø­ÙŠ', 'District', '_', '-']:
                        potential_dist_file = potential_dist_file.replace(w, ' ')
                    
                    # Ù†Ù…Ù„Ø£ Ø§Ù„ÙØ±Ø§Øº Ø¨Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù
                    df_temp['Ø§Ù„Ø­ÙŠ'] = df_temp['Ø§Ù„Ø­ÙŠ'].fillna(potential_dist_file.strip())
                    
                    # ØªÙ†Ø¸ÙŠÙ Ù†Ù‡Ø§Ø¦ÙŠ: Ù„Ùˆ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù Ù†ÙØ³Ù‡ ÙƒØ§Ù† ÙÙŠÙ‡ "Ø±Ø§ÙƒØ²" Ø¨Ø§Ù„ØºÙ„Ø·ØŒ Ù„Ø§ Ù†Ø¹ØªÙ…Ø¯ Ø¹Ù„ÙŠÙ‡ ÙƒØ­ÙŠ
                    df_temp.loc[df_temp['Ø§Ù„Ø­ÙŠ'].str.contains('Ø±Ø§ÙƒØ²', na=False), 'Ø§Ù„Ø­ÙŠ'] = None
                    # =========================================================

                    # 5. Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ©
                    if 'Ø§Ù„Ø³Ø¹Ø±' in df_temp.columns and 'Ø§Ù„Ù…Ø³Ø§Ø­Ø©' in df_temp.columns:
                        for col in ['Ø§Ù„Ø³Ø¹Ø±', 'Ø§Ù„Ù…Ø³Ø§Ø­Ø©', 'Ø¹Ø¯Ø¯_Ø§Ù„ØºØ±Ù']:
                            if col in df_temp.columns:
                                df_temp[col] = df_temp[col].astype(str).str.replace(',', '').str.replace(r'[^\d.]', '', regex=True)
                                df_temp[col] = pd.to_numeric(df_temp[col], errors='coerce')
                        
                        df_temp.dropna(subset=['Ø§Ù„Ø³Ø¹Ø±', 'Ø§Ù„Ù…Ø³Ø§Ø­Ø©'], inplace=True)
                        df_temp = df_temp[df_temp['Ø§Ù„Ù…Ø³Ø§Ø­Ø©'] > 0]
                        
                        df_temp['Ø³Ø¹Ø±_Ø§Ù„Ù…ØªØ±'] = df_temp['Ø§Ù„Ø³Ø¹Ø±'] / df_temp['Ø§Ù„Ù…Ø³Ø§Ø­Ø©']
                        df_temp['Source_File'] = file['name']
                        df_temp['Source_Type'] = source_type
                        df_temp['Data_Category'] = data_cat
                        
                        # Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„Ù†ÙˆØ§Ù‚Øµ
                        for c in ['Ù†ÙˆØ¹_Ø§Ù„Ø¹Ù‚Ø§Ø±_Ø§Ù„Ø®Ø§Ù…', 'Ø§Ù„Ø­Ø§Ù„Ø©', 'Ø¹Ø¯Ø¯_Ø§Ù„ØºØ±Ù', 'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©', 'Ø§Ø³Ù…_Ø§Ù„Ù…Ø·ÙˆØ±', 'Ø¹Ø¯Ø¯_Ø§Ù„ØµÙƒÙˆÙƒ', 'Ø§Ø³Ù…_Ø§Ù„Ù…Ø´Ø±ÙˆØ¹_Ø§Ù„Ø®Ø§Ù…']: 
                            if c not in df_temp.columns: df_temp[c] = None 
                        
                        cols = ['Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©', 'Ø§Ù„Ø­ÙŠ', 'Ø§Ù„Ø³Ø¹Ø±', 'Ø§Ù„Ù…Ø³Ø§Ø­Ø©', 'Ø³Ø¹Ø±_Ø§Ù„Ù…ØªØ±', 
                                'Ù†ÙˆØ¹_Ø§Ù„Ø¹Ù‚Ø§Ø±_Ø§Ù„Ø®Ø§Ù…', 'Ø§Ù„Ø­Ø§Ù„Ø©', 'Ø¹Ø¯Ø¯_Ø§Ù„ØºØ±Ù',
                                'Source_File', 'Source_Type', 'Data_Category', 'Ø§Ø³Ù…_Ø§Ù„Ù…Ø´Ø±ÙˆØ¹_Ø§Ù„Ø®Ø§Ù…']
                        
                        final_cols = [c for c in cols if c in df_temp.columns]
                        all_data.append(df_temp[final_cols])

                except Exception as e:
                    print(f"Skipping {file['name']}: {e}")

            if all_data:
                total_df = pd.concat(all_data, ignore_index=True)
                medians = {}
                if 'Ø§Ù„Ø­ÙŠ' in total_df.columns:
                    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ
                    temp_land = total_df[total_df['Ù†ÙˆØ¹_Ø§Ù„Ø¹Ù‚Ø§Ø±_Ø§Ù„Ø®Ø§Ù…'].astype(str).str.contains('Ø£Ø±Ø¶', na=False)]
                    if not temp_land.empty:
                        medians = temp_land.groupby('Ø§Ù„Ø­ÙŠ')['Ø³Ø¹Ø±_Ø§Ù„Ù…ØªØ±'].median().to_dict()

                # 6. ØªØµÙ†ÙŠÙ Ø§Ù„Ø¹Ù‚Ø§Ø± Ø§Ù„Ù…Ø²Ø¯ÙˆØ¬
                def classify_property(row):
                    raw = str(row.get('Ù†ÙˆØ¹_Ø§Ù„Ø¹Ù‚Ø§Ø±_Ø§Ù„Ø®Ø§Ù…', '')).strip().lower()
                    category = row.get('Data_Category', '')
                    
                    # Ø£) Ø§Ù„Ø¹Ø±ÙˆØ¶
                    if 'Ø¹Ø±ÙˆØ¶' in category or 'Ask' in category:
                        if 'Ø£Ø±Ø¶' in raw or 'land' in raw: return "Ø£Ø±Ø¶"
                        if 'Ø¯ÙˆØ±' in raw: return "Ø¯ÙˆØ±"
                        if 'Ø´Ù‚Ø©' in raw: return "Ø´Ù‚Ø©"
                        if any(x in raw for x in ['ÙÙŠÙ„Ø§', 'ÙÙ„Ù‡', 'villa', 'Ø¨ÙŠØª', 'ØªØ§ÙˆÙ†']): return "ÙÙŠÙ„Ø§"
                        if 'Ø¹Ù…Ø§Ø±Ø©' in raw: return "Ø¹Ù…Ø§Ø±Ø©"
                        
                        # Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù„Ù„Ø¹Ø±ÙˆØ¶ Ø§Ù„ÙØ§Ø±ØºØ© Ø§Ù„Ù†ÙˆØ¹
                        area = row.get('Ø§Ù„Ù…Ø³Ø§Ø­Ø©', 0)
                        if not raw or raw == 'nan' or raw == 'none':
                            if area > 0 and area < 250: return "Ø´Ù‚Ø©"
                            if area > 250: return "ÙÙŠÙ„Ø§"
                        return raw

                    # Ø¨) Ø§Ù„ØµÙÙ‚Ø§Øª
                    else:
                        if 'Ø£Ø±Ø¶' in raw or 'land' in raw: return "Ø£Ø±Ø¶"
                        if any(x in raw for x in ['ÙÙŠÙ„Ø§', 'Ø¨ÙŠØª', 'Ø´Ù‚Ø©', 'Ø¹Ù…Ø§Ø±Ø©', 'Ø¯ÙˆØ±']): return "Ù…Ø¨Ù†ÙŠ"
                        
                        area = row.get('Ø§Ù„Ù…Ø³Ø§Ø­Ø©', 0)
                        ppm = row.get('Ø³Ø¹Ø±_Ø§Ù„Ù…ØªØ±', 0)
                        dist = row.get('Ø§Ù„Ø­ÙŠ', '')
                        avg_land = medians.get(dist, 0)
                        
                        if avg_land > 0 and ppm > (avg_land * 1.5): return "Ù…Ø¨Ù†ÙŠ"
                        return "Ø£Ø±Ø¶"

                total_df['Ù†ÙˆØ¹_Ø§Ù„Ø¹Ù‚Ø§Ø±'] = total_df.apply(classify_property, axis=1)
                return total_df
            
            return pd.DataFrame()
        except: return pd.DataFrame()
