import streamlit as st
import pandas as pd
from google.oauth2 import service_account
from googleapiclient.discovery import build
import io
import csv
import os

# ==========================================
# 1. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
# ==========================================
FOLDER_ID = "1kgzKj9sn8pQVjr78XcN7_iF5KLmflwME"
SCOPES = ['https://www.googleapis.com/auth/drive.readonly']

# Ø§Ù„Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„Ù…Ø­Ø¯Ø« Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ØªÙŠ Ø£Ø±Ø³Ù„ØªÙ‡Ø§
COLUMN_MAPPING = {
    # Ø§Ù„Ø³Ø¹Ø±
    'Ù‚ÙŠÙ…Ø© Ø§Ù„ØµÙÙ‚Ø§Øª': 'Ø§Ù„Ø³Ø¹Ø±', 'Ø§Ù„Ø³Ø¹Ø±': 'Ø§Ù„Ø³Ø¹Ø±', 'Ù…Ø¨Ù„Øº Ø§Ù„ØµÙÙ‚Ø©': 'Ø§Ù„Ø³Ø¹Ø±', 'Price': 'Ø§Ù„Ø³Ø¹Ø±', 
    'Ø³Ø¹Ø± Ø§Ù„ÙˆØ­Ø¯Ø©': 'Ø§Ù„Ø³Ø¹Ø±', 'Total Price': 'Ø§Ù„Ø³Ø¹Ø±',
    
    # Ø§Ù„Ù…Ø³Ø§Ø­Ø© (ØªÙ… Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø³Ø§Ø­Ø© M2)
    'Ø§Ù„Ù…Ø³Ø§Ø­Ø© M2': 'Ø§Ù„Ù…Ø³Ø§Ø­Ø©', 'Ø§Ù„Ù…Ø³Ø§Ø­Ø©': 'Ø§Ù„Ù…Ø³Ø§Ø­Ø©', 'Ø§Ù„Ù…Ø³Ø§Ø­Ø© Ø¨Ø§Ù„Ø£Ù…ØªØ§Ø±': 'Ø§Ù„Ù…Ø³Ø§Ø­Ø©', 
    'Area': 'Ø§Ù„Ù…Ø³Ø§Ø­Ø©', 'Ù…Ø³Ø§Ø­Ø© Ø§Ù„ÙˆØ­Ø¯Ø©': 'Ø§Ù„Ù…Ø³Ø§Ø­Ø©', 'Size': 'Ø§Ù„Ù…Ø³Ø§Ø­Ø©', 
    
    # Ø§Ù„Ø­ÙŠ ÙˆØ§Ù„Ù…Ø¯ÙŠÙ†Ø©
    'Ø§Ù„Ø­ÙŠ': 'Ø§Ù„Ø­ÙŠ', 'Ø§Ø³Ù… Ø§Ù„Ø­ÙŠ': 'Ø§Ù„Ø­ÙŠ', 'District Name': 'Ø§Ù„Ø­ÙŠ', 'Ø§Ù„Ù…ÙˆÙ‚Ø¹': 'Ø§Ù„Ø­ÙŠ',
    'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©': 'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©', 'City': 'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©', 'Ø§Ù„Ù…Ù†Ø·Ù‚Ø©': 'Ø§Ù„Ù…Ù†Ø·Ù‚Ø©',
    
    # Ø§Ù„Ù†ÙˆØ¹ (ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© ØªØµÙ†ÙŠÙ Ø§Ù„Ø¹Ù‚Ø§Ø± ÙˆÙ†ÙˆØ¹ Ø§Ù„Ø¹Ù‚Ø§Ø±)
    'Ù†ÙˆØ¹ Ø§Ù„Ø¹Ù‚Ø§Ø±': 'Ù†ÙˆØ¹_Ø§Ù„Ø¹Ù‚Ø§Ø±_Ø§Ù„Ø®Ø§Ù…', 'ØªØµÙ†ÙŠÙ Ø§Ù„Ø¹Ù‚Ø§Ø±': 'Ù†ÙˆØ¹_Ø§Ù„Ø¹Ù‚Ø§Ø±_Ø§Ù„Ø®Ø§Ù…', 
    'Ø§Ù„ÙˆØ­Ø¯Ø©': 'Ù†ÙˆØ¹_Ø§Ù„Ø¹Ù‚Ø§Ø±_Ø§Ù„Ø®Ø§Ù…', 'Ø§Ù„Ù†ÙˆØ¹': 'Ù†ÙˆØ¹_Ø§Ù„Ø¹Ù‚Ø§Ø±_Ø§Ù„Ø®Ø§Ù…', 'Property Type': 'Ù†ÙˆØ¹_Ø§Ù„Ø¹Ù‚Ø§Ø±_Ø§Ù„Ø®Ø§Ù…',
    
    # Ø¥Ø¶Ø§ÙÙŠ
    'Ø¹Ø¯Ø¯ Ø§Ù„ØµÙƒÙˆÙƒ': 'Ø¹Ø¯Ø¯_Ø§Ù„ØµÙƒÙˆÙƒ', 'Ø§Ù„Ù…Ø·ÙˆØ±': 'Ø§Ø³Ù…_Ø§Ù„Ù…Ø·ÙˆØ±', 'Ø§Ø³Ù… Ø§Ù„Ù…Ø´Ø±ÙˆØ¹': 'Ø§Ø³Ù…_Ø§Ù„Ù…Ø´Ø±ÙˆØ¹'
}

class RealEstateBot:
    def __init__(self):
        self.log_messages = []
        self.files_found_count = 0
        self.creds = self.get_creds()
        self.service = build('drive', 'v3', credentials=self.creds)
        self.df = self.load_data_from_drive()

    def get_creds(self):
        if 'gcp_service_account' in st.secrets:
            return service_account.Credentials.from_service_account_info(st.secrets['gcp_service_account'], scopes=SCOPES)
        elif os.path.exists('credentials.json'):
            return service_account.Credentials.from_service_account_file('credentials.json', scopes=SCOPES)
        else:
            return None

    def load_data_from_drive(self):
        all_data = []
        if not self.creds: return pd.DataFrame()

        try:
            results = self.service.files().list(
                q=f"'{FOLDER_ID}' in parents and trashed=false",
                fields="files(id, name)").execute()
            files = results.get('files', [])
            self.files_found_count = len(files)

            for file in files:
                if not file['name'].lower().endswith('.csv'): continue
                
                try:
                    request = self.service.files().get_media(fileId=file['id'])
                    content_bytes = request.execute()
                    try: content_str = content_bytes.decode('utf-8-sig')
                    except: content_str = content_bytes.decode('utf-16')

                    is_dev = any(x in file['name'].lower() for x in ['dev', 'Ù…Ø·ÙˆØ±', 'brochure', 'projects'])
                    source_type = 'Ù…Ø·ÙˆØ±ÙŠÙ†' if is_dev else 'Ø¹Ø§Ù…'
                    
                    # Ù…Ø­Ø§ÙˆÙ„Ø© Ù‚Ø±Ø§Ø¡Ø© Ø°ÙƒÙŠØ© (Ø³ÙˆØ§Ø¡ ÙƒØ§Ù†Øª ÙÙˆØ§ØµÙ„ Ø¹Ø§Ø¯ÙŠØ© Ø£Ùˆ Ù…Ù†Ù‚ÙˆØ·Ø©)
                    try:
                        # Ù†Ø¬Ø±Ø¨ Ø§Ù„ÙØ§ØµÙ„Ø© Ø§Ù„Ù…Ù†Ù‚ÙˆØ·Ø© Ø£ÙˆÙ„Ø§Ù‹ (Ù„Ø£Ù† Ù…Ù„ÙØ§Øª Ø§Ù„Ø¹Ø¯Ù„ ØºØ§Ù„Ø¨Ø§Ù‹ ØªØ³ØªØ®Ø¯Ù…Ù‡Ø§)
                        df_temp = pd.read_csv(io.StringIO(content_str), sep=';', engine='python')
                        if len(df_temp.columns) <= 1: # Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ù„ÙØµÙ„ØŒ Ù†Ø¬Ø±Ø¨ Ø§Ù„ÙØ§ØµÙ„Ø© Ø§Ù„Ø¹Ø§Ø¯ÙŠØ©
                            df_temp = pd.read_csv(io.StringIO(content_str), sep=',', engine='python')
                    except:
                        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø£Ø®ÙŠØ±Ø© Ø¨ÙØ§ØµÙ„ ØªÙ„Ù‚Ø§Ø¦ÙŠ
                        df_temp = pd.read_csv(io.StringIO(content_str), sep=None, engine='python')

                    if 'MOJ' in file['name'].upper():
                         source_type = 'Ø¹Ø¯Ù„'

                    # ---------------------------------------------
                    # Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØ§Ù„ØªÙˆØ­ÙŠØ¯
                    # ---------------------------------------------
                    df_temp.columns = df_temp.columns.str.strip() # ØªÙ†Ø¸ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù…Ù† Ø§Ù„Ù…Ø³Ø§ÙØ§Øª
                    df_temp.rename(columns=COLUMN_MAPPING, inplace=True)
                    df_temp = df_temp.loc[:, ~df_temp.columns.duplicated()]

                    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø¨Ø¹Ø¯ Ø§Ù„ØªÙˆØ­ÙŠØ¯
                    if 'Ø§Ù„Ø³Ø¹Ø±' in df_temp.columns and 'Ø§Ù„Ù…Ø³Ø§Ø­Ø©' in df_temp.columns:
                        
                        # ÙÙ„ØªØ±Ø© Ø§Ù„Ø±ÙŠØ§Ø¶ (Ø¥Ø°Ø§ ÙˆØ¬Ø¯ Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©)
                        if 'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©' in df_temp.columns:
                            df_temp['Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©'] = df_temp['Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©'].astype(str).str.strip()
                            df_temp = df_temp[df_temp['Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©'] == 'Ø§Ù„Ø±ÙŠØ§Ø¶']

                        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø£Ø±Ù‚Ø§Ù…
                        for col in ['Ø§Ù„Ø³Ø¹Ø±', 'Ø§Ù„Ù…Ø³Ø§Ø­Ø©']:
                            df_temp[col] = df_temp[col].astype(str).str.replace(',', '').str.replace(r'[^\d.]', '', regex=True)
                            df_temp[col] = pd.to_numeric(df_temp[col], errors='coerce')
                        
                        df_temp.dropna(subset=['Ø§Ù„Ø³Ø¹Ø±', 'Ø§Ù„Ù…Ø³Ø§Ø­Ø©'], inplace=True)
                        
                        if not df_temp.empty:
                            df_temp['Ø³Ø¹Ø±_Ø§Ù„Ù…ØªØ±'] = df_temp['Ø§Ù„Ø³Ø¹Ø±'] / df_temp['Ø§Ù„Ù…Ø³Ø§Ø­Ø©']
                            df_temp['Source_File'] = file['name']
                            df_temp['Source_Type'] = source_type
                            if 'Ù†ÙˆØ¹_Ø§Ù„Ø¹Ù‚Ø§Ø±_Ø§Ù„Ø®Ø§Ù…' not in df_temp.columns: df_temp['Ù†ÙˆØ¹_Ø§Ù„Ø¹Ù‚Ø§Ø±_Ø§Ù„Ø®Ø§Ù…'] = "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"

                            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ù„Ø³Ø­Ø¨
                            cols = ['Ø§Ù„Ø­ÙŠ', 'Ø§Ù„Ø³Ø¹Ø±', 'Ø§Ù„Ù…Ø³Ø§Ø­Ø©', 'Ø³Ø¹Ø±_Ø§Ù„Ù…ØªØ±', 'Ù†ÙˆØ¹_Ø§Ù„Ø¹Ù‚Ø§Ø±_Ø§Ù„Ø®Ø§Ù…', 'Source_File', 'Source_Type', 'Ø§Ø³Ù…_Ø§Ù„Ù…Ø·ÙˆØ±', 'Ø¹Ø¯Ø¯_Ø§Ù„ØµÙƒÙˆÙƒ']
                            found_cols = [c for c in cols if c in df_temp.columns]
                            all_data.append(df_temp[found_cols])

                except Exception as e:
                    print(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ù„Ù {file['name']}: {e}")

            if all_data:
                total_df = pd.concat(all_data, ignore_index=True)
                medians = total_df.groupby('Ø§Ù„Ø­ÙŠ')['Ø³Ø¹Ø±_Ø§Ù„Ù…ØªØ±'].median().to_dict()

                # ØªØµÙ†ÙŠÙ Ø°ÙƒÙŠ
                def classify(row):
                    raw = str(row.get('Ù†ÙˆØ¹_Ø§Ù„Ø¹Ù‚Ø§Ø±_Ø§Ù„Ø®Ø§Ù…', '')).strip().lower()
                    if row.get('Source_Type') == 'Ø³ÙˆÙ‚_Ø­Ø§Ù„ÙŠ (Ù…Ø·ÙˆØ±ÙŠÙ†)':
                        if 'Ø´Ù‚Ø©' in raw: return 'Ù…Ø¨Ù†ÙŠ (Ø´Ù‚Ø© - Ù…Ø·ÙˆØ±)'
                        if 'ÙÙŠÙ„Ø§' in raw: return 'Ù…Ø¨Ù†ÙŠ (ÙÙŠÙ„Ø§ - Ù…Ø·ÙˆØ±)'
                        return 'Ø£Ø±Ø¶ (Ù…Ø·ÙˆØ±)'
                    
                    if 'Ø£Ø±Ø¶' in raw: return "Ø£Ø±Ø¶"
                    if 'ØªØ¬Ø§Ø±ÙŠ' in raw: return "Ø£Ø±Ø¶ (ØªØ¬Ø§Ø±ÙŠ)"
                    
                    # ØªØ®Ù…ÙŠÙ†
                    area, ppm, dist = row['Ø§Ù„Ù…Ø³Ø§Ø­Ø©'], row['Ø³Ø¹Ø±_Ø§Ù„Ù…ØªØ±'], row['Ø§Ù„Ø­ÙŠ']
                    if area < 200: return "Ù…Ø¨Ù†ÙŠ (Ø´Ù‚Ø©)"
                    avg = medians.get(dist, 0)
                    if avg > 0 and ppm > (avg * 1.5) and area < 900: return "Ù…Ø¨Ù†ÙŠ (ÙÙŠÙ„Ø§/Ø¨ÙŠØª)"
                    return "Ø£Ø±Ø¶" # Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ

                total_df['Ù†ÙˆØ¹_Ø§Ù„Ø¹Ù‚Ø§Ø±'] = total_df.apply(classify, axis=1)
                return total_df
            return pd.DataFrame()

        except Exception as e:
            st.error(f"Ø®Ø·Ø£ Ø§Ù„Ø§ØªØµØ§Ù„: {e}")
            return pd.DataFrame()

# ==========================================
# 2. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
# ==========================================
st.set_page_config(page_title="Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„Ø¹Ù‚Ø§Ø±ÙŠ Ø§Ù„Ø°ÙƒÙŠ", layout="wide", page_icon="ğŸ¢")

with st.sidebar:
    st.header("âš™ï¸ Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…")
    if st.button("ğŸ”„ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", use_container_width=True, type="primary"):
        st.cache_data.clear()
        st.rerun()
    
    if 'bot' in st.session_state and hasattr(st.session_state.bot, 'df'):
        bot = st.session_state.bot
        st.divider()
        st.markdown(f"**ğŸ“‚ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ©:** {bot.files_found_count}")
        
        if not bot.df.empty:
            st.markdown("### ğŸ“Š Ø­Ø§Ù„Ø© Ø§Ù„Ø³Ø­Ø¨")
            file_stats = bot.df['Source_File'].value_counts().reset_index()
            file_stats.columns = ['Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù', 'Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙ‚Ø§Øª']
            st.dataframe(file_stats, hide_index=True, use_container_width=True)
            st.caption(f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØµÙÙ‚Ø§Øª: {len(bot.df):,}")
        else:
            st.error("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø³Ø­Ø¨ Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª. ØªØ£ÙƒØ¯ Ù…Ù† ØªØ·Ø§Ø¨Ù‚ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©.")

st.title("ğŸ§ Ù…Ø¯Ù‚Ù‚ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ù‚Ø§Ø±ÙŠØ©")

if 'bot' not in st.session_state:
    with st.spinner("Ø¬Ø§Ø±ÙŠ Ù‚Ø±Ø§Ø¡Ø© ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª..."):
        try:
            st.session_state.bot = RealEstateBot()
        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£: {e}")

if 'bot' in st.session_state and hasattr(st.session_state.bot, 'df'):
    df = st.session_state.bot.df
    
    if df.empty:
        st.warning("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø¹Ø±Ø¶.")
    else:
        # Ø§Ù„ÙÙ„ØªØ±Ø©
        st.markdown("### ğŸ§¹ ÙÙ„ØªØ±Ø© Ø§Ù„Ø£Ø³Ø¹Ø§Ø±")
        c1, c2 = st.columns(2)
        with c1: min_p = st.number_input("Ø£Ù‚Ù„ Ø³Ø¹Ø± Ù„Ù„Ù…ØªØ±:", value=100, step=100)
        with c2: max_p = st.number_input("Ø£Ø¹Ù„Ù‰ Ø³Ø¹Ø± Ù„Ù„Ù…ØªØ±:", value=50000, step=1000)

        clean_df = df[(df['Ø³Ø¹Ø±_Ø§Ù„Ù…ØªØ±'] >= min_p) & (df['Ø³Ø¹Ø±_Ø§Ù„Ù…ØªØ±'] <= max_p)].copy()
        
        st.divider()
        st.markdown("### ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø­ÙŠØ§Ø¡")
        
        sc1, sc2 = st.columns([3, 1])
        search = sc1.text_input("Ø§Ø³Ù… Ø§Ù„Ø­ÙŠ:", "Ø§Ù„Ù…Ù„Ù‚Ø§")
        
        if sc2.button("ØªØ­Ù„ÙŠÙ„ ğŸ“Š", use_container_width=True, type="primary") or search:
            res = clean_df[clean_df['Ø§Ù„Ø­ÙŠ'].astype(str).str.contains(search, na=False)]
            
            if res.empty:
                st.info(f"Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ Ù„Ø­ÙŠ '{search}'")
            else:
                l_df = res[res['Ù†ÙˆØ¹_Ø§Ù„Ø¹Ù‚Ø§Ø±'].str.contains('Ø£Ø±Ø¶', na=False)]
                b_df = res[res['Ù†ÙˆØ¹_Ø§Ù„Ø¹Ù‚Ø§Ø±'].str.contains('Ù…Ø¨Ù†ÙŠ', na=False)]
                
                m1, m2, m3, m4 = st.columns(4)
                m1.metric("Ø£Ø±Ø§Ø¶ÙŠ", f"{len(l_df):,}")
                m2.metric("Ù…ØªÙˆØ³Ø· Ø£Ø±Ø¶", f"{l_df['Ø³Ø¹Ø±_Ø§Ù„Ù…ØªØ±'].median():,.0f}")
                m3.metric("Ù…Ø¨Ø§Ù†ÙŠ", f"{len(b_df):,}")
                m4.metric("Ù…ØªÙˆØ³Ø· Ù…Ø¨Ù†Ù‰", f"{b_df['Ø³Ø¹Ø±_Ø§Ù„Ù…ØªØ±'].median():,.0f}")
                
                st.markdown("#### ØªÙØ§ØµÙŠÙ„ Ø§Ù„ØµÙÙ‚Ø§Øª:")
                
                # ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù„Ù„Ø¹Ø±Ø¶ (Ø¨Ù…Ø§ ÙÙŠÙ‡Ø§ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙƒÙˆÙƒ Ø§Ù„Ø¬Ø¯ÙŠØ¯)
                view_cols = ['Ø§Ù„Ø­ÙŠ', 'Ù†ÙˆØ¹_Ø§Ù„Ø¹Ù‚Ø§Ø±', 'Ø§Ù„Ù…Ø³Ø§Ø­Ø©', 'Ø§Ù„Ø³Ø¹Ø±', 'Ø³Ø¹Ø±_Ø§Ù„Ù…ØªØ±', 'Source_File']
                if 'Ø¹Ø¯Ø¯_Ø§Ù„ØµÙƒÙˆÙƒ' in res.columns: view_cols.insert(2, 'Ø¹Ø¯Ø¯_Ø§Ù„ØµÙƒÙˆÙƒ')
                
                st.dataframe(
                    res[view_cols].style.format({'Ø§Ù„Ø³Ø¹Ø±':'{:,.0f}', 'Ø³Ø¹Ø±_Ø§Ù„Ù…ØªØ±':'{:,.0f}'}), 
                    use_container_width=True
                )
                
